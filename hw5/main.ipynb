{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Classification Problem\n",
    "\n",
    "To solve in tf.keras, PyTorch, PyTorch Lightning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T16:52:48.274384Z",
     "iopub.status.busy": "2024-12-07T16:52:48.273933Z",
     "iopub.status.idle": "2024-12-07T16:53:00.310323Z",
     "shell.execute_reply": "2024-12-07T16:53:00.308555Z",
     "shell.execute_reply.started": "2024-12-07T16:52:48.274347Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -qqq pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-07T16:53:30.678533Z",
     "iopub.status.busy": "2024-12-07T16:53:30.678135Z",
     "iopub.status.idle": "2024-12-07T16:53:30.686385Z",
     "shell.execute_reply": "2024-12-07T16:53:30.685038Z",
     "shell.execute_reply.started": "2024-12-07T16:53:30.678498Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' \n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import logging\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.WARNING)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", \".*does not have many workers.*\")\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data load, and divide into train, valdation and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T16:53:37.007072Z",
     "iopub.status.busy": "2024-12-07T16:53:37.006617Z",
     "iopub.status.idle": "2024-12-07T16:53:37.029313Z",
     "shell.execute_reply": "2024-12-07T16:53:37.027970Z",
     "shell.execute_reply.started": "2024-12-07T16:53:37.007033Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 102, val: 22, test:26\n"
     ]
    }
   ],
   "source": [
    "def load_iris():\n",
    "    iris = datasets.load_iris();\n",
    "    x = iris.data\n",
    "    y = iris.target\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.17,random_state=42)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train,y_train,test_size=0.17,random_state=42)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_val = scaler.transform(x_val)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n",
    "x_train, x_val, x_test, y_train, y_val, y_test = load_iris()\n",
    "\n",
    "batch_size = 8\n",
    "max_epochs = 20\n",
    "print(f'train: {len(x_train)}, val: {len(x_val)}, test:{len(x_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T16:54:33.488689Z",
     "iopub.status.busy": "2024-12-07T16:54:33.488272Z",
     "iopub.status.idle": "2024-12-07T16:54:37.977227Z",
     "shell.execute_reply": "2024-12-07T16:54:37.975834Z",
     "shell.execute_reply.started": "2024-12-07T16:54:33.488652Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch: 19.\n",
      "Keras Test accuracy: 0.8846153616905212\n"
     ]
    }
   ],
   "source": [
    "def _keras():\n",
    "    num_classes = 3\n",
    "    _y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "    _y_val = tf.keras.utils.to_categorical(y_val, num_classes)\n",
    "    _y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.Input(shape=(x_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(16, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(8, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2, restore_best_weights=True, verbose=1)\n",
    "    tbcb = tf.keras.callbacks.TensorBoard(log_dir=\"logs/1/keras\", histogram_freq=0)\n",
    "    model.fit(x_train, _y_train, epochs=max_epochs, batch_size=batch_size, validation_data=(x_val, _y_val), callbacks=[early_stopping, tbcb], verbose=0)\n",
    "    test_loss, test_acc = model.evaluate(x_test, _y_test, verbose=0)\n",
    "    print(f\"Keras Test accuracy: {test_acc}\")\n",
    "\n",
    "_keras()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert data to tensor for PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T16:53:44.665142Z",
     "iopub.status.busy": "2024-12-07T16:53:44.664634Z",
     "iopub.status.idle": "2024-12-07T16:53:44.706121Z",
     "shell.execute_reply": "2024-12-07T16:53:44.704710Z",
     "shell.execute_reply.started": "2024-12-07T16:53:44.665102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "x_train, x_val, x_test, y_train, y_val, y_test = load_iris()\n",
    "\n",
    "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "x_val = torch.tensor(x_val, dtype=torch.float32)\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(TensorDataset(x_val, y_val), batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T16:54:14.180207Z",
     "iopub.status.busy": "2024-12-07T16:54:14.179758Z",
     "iopub.status.idle": "2024-12-07T16:54:14.494787Z",
     "shell.execute_reply": "2024-12-07T16:54:14.493345Z",
     "shell.execute_reply.started": "2024-12-07T16:54:14.180168Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered at epoch 9\n",
      "Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def _torch():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"using device: {device}\")\n",
    "    \n",
    "    class IrisNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(IrisNet, self).__init__()\n",
    "            self.fc1 = nn.Linear(4, 16)\n",
    "            self.bn1 = nn.BatchNorm1d(16)\n",
    "            self.dropout1 = nn.Dropout(0.3)\n",
    "            self.fc2 = nn.Linear(16, 8)\n",
    "            self.bn2 = nn.BatchNorm1d(8)\n",
    "            self.dropout2 = nn.Dropout(0.3)\n",
    "            self.fc3 = nn.Linear(8, 3)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.dropout1(torch.relu(self.bn1(self.fc1(x))))\n",
    "            x = self.dropout2(torch.relu(self.bn2(self.fc2(x))))\n",
    "            x = self.fc3(x)\n",
    "            return x\n",
    "\n",
    "    model = IrisNet().to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    writer = SummaryWriter(log_dir='logs/1/torch')\n",
    "\n",
    "    # Early Stopping parameters\n",
    "    patience = 2  \n",
    "    best_val_loss = float('inf')  \n",
    "    epochs_without_improvement = 0  \n",
    "    best_model_state = None\n",
    "\n",
    "    epochs = max_epochs\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for feature, labels in train_loader:\n",
    "            feature, labels = feature.to(device), labels.to(device)\n",
    "            outputs = model(feature)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for feature, labels in val_loader:\n",
    "                feature, labels = feature.to(device), labels.to(device)\n",
    "                outputs = model(feature)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_accuracy = correct / total\n",
    "        writer.add_scalar('epoch_loss', val_loss / len(val_loader), epoch)\n",
    "        writer.add_scalar('epoch_accuracy', val_accuracy, epoch)\n",
    "\n",
    "        # Early stopping check\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_without_improvement = 0\n",
    "            # Save the best model\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            epochs_without_improvement += 1\n",
    "            if epochs_without_improvement >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for feature, labels in test_loader:\n",
    "            feature, labels = feature.to(device), labels.to(device)\n",
    "            outputs = model(feature)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "_torch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T16:54:09.650049Z",
     "iopub.status.busy": "2024-12-07T16:54:09.649611Z",
     "iopub.status.idle": "2024-12-07T16:54:10.706233Z",
     "shell.execute_reply": "2024-12-07T16:54:10.705072Z",
     "shell.execute_reply.started": "2024-12-07T16:54:09.650010Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lightning Test Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def _pl():\n",
    "    writer = SummaryWriter(log_dir='logs/1/pl')\n",
    "    \n",
    "    class IrisClassifier(pl.LightningModule):\n",
    "\n",
    "        def __init__(self, input_size=4, \n",
    "                    hidden_size1=16,\n",
    "                    hidden_size2=8,\n",
    "                    output_size=3,\n",
    "                    lr=0.01):\n",
    "            super(IrisClassifier, self).__init__()\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(input_size, hidden_size1),\n",
    "                nn.BatchNorm1d(hidden_size1),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(hidden_size1, hidden_size2),\n",
    "                nn.BatchNorm1d(hidden_size2),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(hidden_size2, output_size)\n",
    "            )\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "            self.lr = lr\n",
    "            self.test_acc = []\n",
    "            self.val_acc = []\n",
    "            self.val_loss = []\n",
    "        \n",
    "        def forward(self, x):\n",
    "            return self.model(x)\n",
    "        \n",
    "        def training_step(self, batch, batch_idx):\n",
    "            x, y = batch\n",
    "            y_hat = self(x)\n",
    "            loss = self.criterion(y_hat, y)\n",
    "            # self.log(\"loss/train\", loss)\n",
    "            return loss\n",
    "        \n",
    "        def validation_step(self, batch, batch_idx):\n",
    "            loss, acc = self.validate(batch)\n",
    "            self.val_acc += [acc.cpu().numpy()]\n",
    "            self.val_loss += [loss.cpu().numpy()]\n",
    "            self.log(\"val_loss\", loss, prog_bar=False)\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def validate(self, batch):\n",
    "            x, y = batch\n",
    "            y_hat = self.forward(x)\n",
    "            loss = self.criterion(y_hat, y)\n",
    "            acc = (y_hat.argmax(dim=1)==y).float().mean()\n",
    "            return loss, acc\n",
    "\n",
    "        def test_step(self, batch, batch_idx):\n",
    "            loss, acc = self.validate(batch)\n",
    "            self.test_acc += [acc.cpu().numpy()]\n",
    "        \n",
    "        def configure_optimizers(self):\n",
    "            return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    "        def evaluate(self):\n",
    "            return np.array(self.test_acc).mean()\n",
    "        \n",
    "        def on_validation_epoch_end(self):\n",
    "            writer.add_scalar('epoch_loss', np.array(self.val_loss).mean(), self.current_epoch)\n",
    "            writer.add_scalar('epoch_accuracy', np.array(self.val_acc).mean(), self.current_epoch)\n",
    "            self.val_loss.clear()\n",
    "            self.val_acc.clear()\n",
    "    \n",
    "    model = IrisClassifier()\n",
    "    early_stopping = pl.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, verbose=True, mode=\"min\")\n",
    "    trainer = pl.Trainer(max_epochs=max_epochs, log_every_n_steps=10, callbacks=[early_stopping], enable_progress_bar=False)\n",
    "    trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "    trainer.test(model, dataloaders=test_loader, verbose=False)\n",
    "    acc = model.evaluate()\n",
    "    print(f\"Lightning Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "_pl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/discussions/general/151033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T16:55:29.816647Z",
     "iopub.status.busy": "2024-12-07T16:55:29.816211Z",
     "iopub.status.idle": "2024-12-07T16:55:34.841480Z",
     "shell.execute_reply": "2024-12-07T16:55:34.840386Z",
     "shell.execute_reply.started": "2024-12-07T16:55:29.816610Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-b4db8be01f3b4373\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-b4db8be01f3b4373\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir_spec=keras:logs/1/keras/validation,torch:logs/1/torch,lightning:logs/1/pl"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
